{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport seaborn as sns\nfrom skimage import io\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import load_img\n\nfrom IPython.display import HTML\nfrom IPython.display import clear_output\nimport warnings\nwarnings.simplefilter(\"ignore\")","metadata":{"id":"PfD15DP17ea8","execution":{"iopub.status.busy":"2022-07-31T11:06:57.673557Z","iopub.execute_input":"2022-07-31T11:06:57.675932Z","iopub.status.idle":"2022-07-31T11:07:04.526323Z","shell.execute_reply.started":"2022-07-31T11:06:57.675850Z","shell.execute_reply":"2022-07-31T11:07:04.525345Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Скачивание данных с помощью Kaggle API\n\nhttps://www.kaggle.com/docs/api\n\nhttps://www.kaggle.com/general/74235","metadata":{"id":"ePHLhzd0SK0D"}},{"cell_type":"code","source":"# !pip install -q kaggle\n\n# from google.colab import files\n\n# files.upload()","metadata":{"id":"qgC5XOYLpyST","outputId":"0c44441e-2c1a-4bdb-c88f-33ef71f75526","execution":{"iopub.status.busy":"2022-07-31T11:07:04.528228Z","iopub.execute_input":"2022-07-31T11:07:04.528933Z","iopub.status.idle":"2022-07-31T11:07:04.537632Z","shell.execute_reply.started":"2022-07-31T11:07:04.528894Z","shell.execute_reply":"2022-07-31T11:07:04.536337Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Coco Dataset","metadata":{"id":"J4GAwWB2CWfA"}},{"cell_type":"markdown","source":"Первым набором данных является датасет [COCO](https://cocodataset.org/#download)\n\nCOCO - это крупномасштабный набор данных для обнаружения объектов, сегментации и субтитров. COCO имеет несколько особенностей:\n\n* Сегментация объектов\n* Признание в контексте\n* Сегментация суперпиксельного материала\n* 330 тысяч изображений (>200K помеченных) миллиона экземпляров объектов\n* 80 категорий объектов\n* 91 категория товаров\n* 5 подписей к изображению\n* 250 000 человек с ключевыми точками\n\n\nФормат для набора данных обнаружения объектов COCO задокументирован в формате [COCO Data Format](https://cocodataset.org/#format-data). Данные COCO состоят из пяти разделов информации, которые предоставляют информацию для всего набора данных.\n\n1. Информация – общая информация о наборе данных.\n\n2. Лицензии – информация о лицензии для изображений в наборе данных.\n\n3. Изображения – список изображений в наборе данных.\n\n4. Аннотации – список аннотаций (включая ограничивающие рамки), которые присутствуют на всех изображениях в наборе данных.\n\n5. Категории - список категорий этикеток.\n\nCOCO хранит аннотации в формате JSON.\n\nВ официальном документе COCO говорится, что он имеет пять функций: обнаружение объектов, обнаружение ключевых точек, сегментация материала, паноптическая сегментация и субтитры к изображениям.\n\nВ данном ноутбуке будет использована разновидность COCO датасета с kaggle: [COCO-Person-Segmentation](https://www.kaggle.com/datasets/oishee30/cocopersonsegmentation) со следующей структурой\n\n    cocopersonsegmentation\n        ├── train2017_ann\n        ├── train2017_new\n        ├── val2017_ann\n        └── val2017_new","metadata":{}},{"cell_type":"markdown","source":"В данной модификации уже произведено разбиение изображений на тренировочную и валидационные выборки, а также аннотации (в данном случае маски) к ним\n\n    ","metadata":{}},{"cell_type":"code","source":"# ! mkdir ~/.kaggle                 #make directory(folder) named .kaggle\n \n# ! cp kaggle.json ~/.kaggle/       #add file to that folder\n \n# ! chmod 600 ~/.kaggle/kaggle.json        #Change the permissions of the file.","metadata":{"id":"UFb3m87kRJFB","execution":{"iopub.status.busy":"2022-07-31T11:07:04.538979Z","iopub.execute_input":"2022-07-31T11:07:04.539726Z","iopub.status.idle":"2022-07-31T11:07:04.561288Z","shell.execute_reply.started":"2022-07-31T11:07:04.539691Z","shell.execute_reply":"2022-07-31T11:07:04.560335Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n# ! kaggle datasets download oishee30/cocopersonsegmentation\n\n# print(os.listdir('/content'))","metadata":{"id":"XU6GF4DwWbqX","outputId":"68afc540-6baa-4e09-9ec8-a4dd4ab27cb2","execution":{"iopub.status.busy":"2022-07-31T11:07:04.564418Z","iopub.execute_input":"2022-07-31T11:07:04.564875Z","iopub.status.idle":"2022-07-31T11:07:04.571956Z","shell.execute_reply.started":"2022-07-31T11:07:04.564836Z","shell.execute_reply":"2022-07-31T11:07:04.570820Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# ! mkdir data        #making directory data\n \n# ! unzip cocopersonsegmentation.zip -d data            #unzipping data into data directory","metadata":{"id":"b_hZ4g9FWbwu","outputId":"8a8b1b20-e384-422a-a3d0-0b27a43d307f","execution":{"iopub.status.busy":"2022-07-31T11:07:04.573652Z","iopub.execute_input":"2022-07-31T11:07:04.574094Z","iopub.status.idle":"2022-07-31T11:07:04.582464Z","shell.execute_reply.started":"2022-07-31T11:07:04.574056Z","shell.execute_reply":"2022-07-31T11:07:04.581514Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# os.remove('/content/cocopersonsegmentation.zip')\n# print(os.listdir('/content'))","metadata":{"id":"sgx5MlZDmSpP","outputId":"ac4e530c-77d4-46ae-886e-aceb07b138d5","execution":{"iopub.status.busy":"2022-07-31T11:07:04.583823Z","iopub.execute_input":"2022-07-31T11:07:04.584301Z","iopub.status.idle":"2022-07-31T11:07:04.593946Z","shell.execute_reply.started":"2022-07-31T11:07:04.584265Z","shell.execute_reply":"2022-07-31T11:07:04.593012Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/')","metadata":{"id":"TI9AHdt_Y4JR","outputId":"91623b48-4848-4ea5-bdd0-a02d29bb6492","execution":{"iopub.status.busy":"2022-07-31T11:07:04.597337Z","iopub.execute_input":"2022-07-31T11:07:04.597701Z","iopub.status.idle":"2022-07-31T11:07:04.609531Z","shell.execute_reply.started":"2022-07-31T11:07:04.597672Z","shell.execute_reply":"2022-07-31T11:07:04.608624Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# path = '/content/data'\n# for folder in os.listdir(path):\n#   if '.txt' not in folder:\n#     print('No of images in',folder,len(os.listdir(path+'/'+folder)))","metadata":{"id":"_cFIXBNJdzG1","execution":{"iopub.status.busy":"2022-07-31T11:07:04.612569Z","iopub.execute_input":"2022-07-31T11:07:04.613038Z","iopub.status.idle":"2022-07-31T11:07:04.618472Z","shell.execute_reply.started":"2022-07-31T11:07:04.613001Z","shell.execute_reply":"2022-07-31T11:07:04.617500Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"xpath_coco = '../input/cocopersonsegmentation/train2017_new'\nypath_coco = '../input/cocopersonsegmentation/train2017_ann'\nx_test_path = '../input/cocopersonsegmentation/val2017_new'\ny_test_path = '../input/cocopersonsegmentation/val2017_ann'","metadata":{"id":"0nKjOo66GmXT","execution":{"iopub.status.busy":"2022-07-31T11:07:04.619775Z","iopub.execute_input":"2022-07-31T11:07:04.620233Z","iopub.status.idle":"2022-07-31T11:07:04.629264Z","shell.execute_reply.started":"2022-07-31T11:07:04.620197Z","shell.execute_reply":"2022-07-31T11:07:04.628273Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_img_paths_coco = sorted([os.path.join(xpath_coco, fname) for fname in os.listdir(xpath_coco)])\ntarget_img_paths_coco = sorted([os.path.join(ypath_coco, fname) for fname in os.listdir(ypath_coco)])\n\nprint(len(input_img_paths_coco), len(target_img_paths_coco))\nfor input_path, target_path in zip(input_img_paths_coco[:4], target_img_paths_coco[:4]):\n    print(input_path, \"|\", target_path)","metadata":{"id":"DsKTmeOMDI63","outputId":"57814b2e-5ec4-4ecf-d5ad-a2331bd864e6","execution":{"iopub.status.busy":"2022-07-31T11:07:04.634226Z","iopub.execute_input":"2022-07-31T11:07:04.634506Z","iopub.status.idle":"2022-07-31T11:07:06.912977Z","shell.execute_reply.started":"2022-07-31T11:07:04.634483Z","shell.execute_reply":"2022-07-31T11:07:06.912006Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Другой датасет","metadata":{"id":"nb4htN3C8mbJ"}},{"cell_type":"markdown","source":"Второй датасет [Person segmentation dataset](https://www.kaggle.com/datasets/furkankati/person-segmentation-dataset) предназначен для сегментации изображений людей. Включает только фотографии людей с разных ракурсов.\n\nНабор данных составлен из https://vuhcs.github.io/ и имеет следующую структуру:\n\n    person-segmentation-dataset\n    └── Training\n        ├── Output\n        └── input\n\n\nВ папке *input* есть цветные изображения людей. В папке *Output* есть изображения с аннотациями с тем же именем и размером. Аннотации - это изображения серого цвета. Значения пикселей аннотации равны 255. 255 для лица и 0 для фона.","metadata":{}},{"cell_type":"code","source":"# ! kaggle datasets download furkankati/person-segmentation-dataset\n\n# print(os.listdir('/content'))","metadata":{"id":"k_ozMqlM8ou8","outputId":"a3ee350a-0cb4-44b4-dde0-f9d178695490","execution":{"iopub.status.busy":"2022-07-31T11:07:06.917144Z","iopub.execute_input":"2022-07-31T11:07:06.919383Z","iopub.status.idle":"2022-07-31T11:07:06.925108Z","shell.execute_reply.started":"2022-07-31T11:07:06.919346Z","shell.execute_reply":"2022-07-31T11:07:06.924170Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# ! unzip person-segmentation-dataset.zip -d data","metadata":{"id":"fLB05X5M9fr8","outputId":"56239e66-9613-4ecc-ad5a-301fa711ecd7","execution":{"iopub.status.busy":"2022-07-31T11:07:06.928375Z","iopub.execute_input":"2022-07-31T11:07:06.929978Z","iopub.status.idle":"2022-07-31T11:07:06.936673Z","shell.execute_reply.started":"2022-07-31T11:07:06.929941Z","shell.execute_reply":"2022-07-31T11:07:06.935793Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# os.remove('/content/person-segmentation-dataset.zip')\n# print(os.listdir('/content'))","metadata":{"id":"QJiMwOCP9fwy","outputId":"cffce96f-c0aa-4d85-bd2b-baaf007c4326","execution":{"iopub.status.busy":"2022-07-31T11:07:06.938017Z","iopub.execute_input":"2022-07-31T11:07:06.939360Z","iopub.status.idle":"2022-07-31T11:07:06.948169Z","shell.execute_reply.started":"2022-07-31T11:07:06.939228Z","shell.execute_reply":"2022-07-31T11:07:06.947245Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# os.listdir('/content/data/')","metadata":{"id":"B9NXpUqEGVaQ","outputId":"c76aa229-983e-4e26-e2e0-d444c48f1ffa","execution":{"iopub.status.busy":"2022-07-31T11:07:06.949481Z","iopub.execute_input":"2022-07-31T11:07:06.950144Z","iopub.status.idle":"2022-07-31T11:07:06.958870Z","shell.execute_reply.started":"2022-07-31T11:07:06.950111Z","shell.execute_reply":"2022-07-31T11:07:06.957894Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"path = '../input/person-segmentation-dataset/Training/'\nfor folder in os.listdir(path):\n    if ('.txt' not in folder) and ('.hdf' not in folder) :\n        print('No of images in',folder,len(os.listdir(path+folder)))","metadata":{"id":"O0MN_Fhg9WO5","outputId":"b260457d-560d-4b2f-f98c-8c6b693d4881","execution":{"iopub.status.busy":"2022-07-31T11:07:06.959902Z","iopub.execute_input":"2022-07-31T11:07:06.960345Z","iopub.status.idle":"2022-07-31T11:07:09.530471Z","shell.execute_reply.started":"2022-07-31T11:07:06.960309Z","shell.execute_reply":"2022-07-31T11:07:09.528917Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"xpath_89k = '../input/person-segmentation-dataset/Training/input/'\nypath_89k = '../input/person-segmentation-dataset/Training/Output/'\n \n# input_img_paths_89k = sorted([os.path.join(xpath_89k, fname) for fname in os.listdir(xpath_89k)])\n# target_img_paths_89k = sorted([os.path.join(ypath_89k, fname) for fname in os.listdir(ypath_89k)])","metadata":{"id":"tl7-olDn_9OO","execution":{"iopub.status.busy":"2022-07-31T11:07:09.534415Z","iopub.execute_input":"2022-07-31T11:07:09.534836Z","iopub.status.idle":"2022-07-31T11:07:09.541409Z","shell.execute_reply.started":"2022-07-31T11:07:09.534800Z","shell.execute_reply":"2022-07-31T11:07:09.540242Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"input_img_paths_89k = sorted([os.path.join(xpath_89k, fname) for fname in os.listdir(xpath_89k)])\ntarget_img_paths_89k = sorted([os.path.join(ypath_89k, fname) for fname in os.listdir(ypath_89k)])\n\nprint(len(input_img_paths_89k), len(target_img_paths_89k))\nfor input_path, target_path in zip(input_img_paths_89k[:4], target_img_paths_89k[:4]):\n    print(input_path, \"|\", target_path)","metadata":{"id":"K582y4M6IPVe","outputId":"b6f9ea5e-1355-4bdb-9360-72eb8c7a8c54","execution":{"iopub.status.busy":"2022-07-31T11:07:09.543491Z","iopub.execute_input":"2022-07-31T11:07:09.544377Z","iopub.status.idle":"2022-07-31T11:07:10.052450Z","shell.execute_reply.started":"2022-07-31T11:07:09.544340Z","shell.execute_reply":"2022-07-31T11:07:10.051452Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Подготовка данных к обучению\n\n","metadata":{"id":"mL4h_J2KmiG1"}},{"cell_type":"code","source":"train_input_img_paths = input_img_paths_coco.copy()\ntarget_input_img_paths = target_img_paths_coco.copy()\n\nprint(len(train_input_img_paths), len(target_input_img_paths))","metadata":{"id":"8owOpmubK89v","outputId":"b876e77d-bb37-4a24-a831-e891e33017e2","execution":{"iopub.status.busy":"2022-07-31T11:07:10.053950Z","iopub.execute_input":"2022-07-31T11:07:10.054538Z","iopub.status.idle":"2022-07-31T11:07:10.064025Z","shell.execute_reply.started":"2022-07-31T11:07:10.054501Z","shell.execute_reply":"2022-07-31T11:07:10.063114Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for img in input_img_paths_89k:\n    train_input_img_paths.append(img)\n\n    \nfor img in target_img_paths_89k:\n    target_input_img_paths.append(img)\n\nprint(len(train_input_img_paths), len(target_input_img_paths))","metadata":{"id":"PhzKhn_NB46-","outputId":"b6958ae7-1565-4a14-fc01-e16168d92ac8","execution":{"iopub.status.busy":"2022-07-31T11:07:10.065439Z","iopub.execute_input":"2022-07-31T11:07:10.065792Z","iopub.status.idle":"2022-07-31T11:07:10.108182Z","shell.execute_reply.started":"2022-07-31T11:07:10.065756Z","shell.execute_reply":"2022-07-31T11:07:10.107233Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_input_img_paths = sorted(train_input_img_paths)    #sorting\ntrain_target_img_paths = sorted(target_input_img_paths)   #sorting\n \nval_input_img_paths = sorted([os.path.join(x_test_path, fname) for fname in os.listdir(x_test_path)])\nval_target_img_paths = sorted([os.path.join(y_test_path, fname) for fname in os.listdir(y_test_path)])\n \nprint(\"Number of training samples:\", len(train_input_img_paths))\nprint(\"Number of validation samples:\", len(val_input_img_paths))\n \nfor input_path, target_path in zip(train_input_img_paths[:4], train_target_img_paths[:4]):\n    print(input_path, \"|\", target_path)","metadata":{"id":"hbwZvaMexDCP","outputId":"8c5acb8c-2e8a-4683-c93c-66699869312a","execution":{"iopub.status.busy":"2022-07-31T11:07:10.109756Z","iopub.execute_input":"2022-07-31T11:07:10.110141Z","iopub.status.idle":"2022-07-31T11:07:10.460592Z","shell.execute_reply.started":"2022-07-31T11:07:10.110105Z","shell.execute_reply":"2022-07-31T11:07:10.459602Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"n_images = 5\nfor i in np.random.randint(0,len(train_input_img_paths),n_images):\n \n    fig = plt.figure(figsize=(12,6))\n    fig.tight_layout()\n    plt.subplot(1,2,1)\n    img = plt.imread(train_input_img_paths[i])\n    plt.imshow(img)\n    plt.title('Image')\n \n    plt.subplot(1,2,2)\n    img = plt.imread(train_target_img_paths[i])\n    plt.imshow(img)\n    plt.title('Mask')\n \n    plt.show()\n    print()","metadata":{"id":"7GidnY8HMjA9","outputId":"acfae04f-c497-4b05-8bbc-2ab05b22ac26","execution":{"iopub.status.busy":"2022-07-31T11:07:10.462127Z","iopub.execute_input":"2022-07-31T11:07:10.462469Z","iopub.status.idle":"2022-07-31T11:07:12.507559Z","shell.execute_reply.started":"2022-07-31T11:07:10.462435Z","shell.execute_reply":"2022-07-31T11:07:12.506650Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"mask = plt.imread(train_target_img_paths[0])\nprint(np.unique(mask, return_counts= True))\nprint(mask.shape)\nsns.countplot(mask.ravel())\nplt.show()","metadata":{"id":"sI7S478rNwf5","outputId":"e1ddc87b-57de-42da-e8ad-461163def5be","execution":{"iopub.status.busy":"2022-07-31T11:07:12.509029Z","iopub.execute_input":"2022-07-31T11:07:12.509913Z","iopub.status.idle":"2022-07-31T11:07:12.675511Z","shell.execute_reply.started":"2022-07-31T11:07:12.509871Z","shell.execute_reply":"2022-07-31T11:07:12.674350Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"mask = plt.imread(train_target_img_paths[-1])\nprint(np.unique(mask, return_counts= True))\nprint(mask.shape)\nsns.countplot(mask.ravel())\nplt.show()","metadata":{"id":"rZV24HO_N4ZL","outputId":"ebba2c05-9e9f-4eb6-e1a7-4d28217f2558","execution":{"iopub.status.busy":"2022-07-31T11:07:12.677000Z","iopub.execute_input":"2022-07-31T11:07:12.677594Z","iopub.status.idle":"2022-07-31T11:07:12.843098Z","shell.execute_reply.started":"2022-07-31T11:07:12.677542Z","shell.execute_reply":"2022-07-31T11:07:12.842090Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nimg_size = (256,256)\n\nclass Data_Gen(keras.utils.Sequence):\n    \"\"\"Helper function to iterate over the data (as Numpy arrays).\"\"\"\n \n    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.input_img_paths = input_img_paths\n        self.target_img_paths = target_img_paths\n \n    def __len__(self):\n        return len(self.target_img_paths) // self.batch_size                    # 64115//32\n \n    def __getitem__(self, idx):\n        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n        i = idx * self.batch_size                                                            # 0\n        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]                # [0: 0+32]\n        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n \n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")           #(32,256,256,3)\n        for j, path in enumerate(batch_input_img_paths):\n            img = load_img(path, target_size=self.img_size)\n            img = np.array(img)/255\n            x[j] = img\n \n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")             #(32,256,256,1)\n        for j, path in enumerate(batch_target_img_paths):\n            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")        #(256,256)\n            img = np.array(img)\n            img[img!=0] = 1\n            y[j] = np.expand_dims(img, 2)                                                  #(256,256,1)\n \n        return x, y","metadata":{"id":"sO7q2JTf2quB","execution":{"iopub.status.busy":"2022-07-31T11:07:12.847782Z","iopub.execute_input":"2022-07-31T11:07:12.850672Z","iopub.status.idle":"2022-07-31T11:07:12.869774Z","shell.execute_reply.started":"2022-07-31T11:07:12.850592Z","shell.execute_reply":"2022-07-31T11:07:12.868505Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# checking gererator function\ntrain_gen = Data_Gen(batch_size, img_size, train_input_img_paths, train_target_img_paths)\nval_gen = Data_Gen(batch_size, img_size, val_input_img_paths, val_target_img_paths)\nx, y = train_gen.__getitem__(0)\nprint(x.shape, y.shape)","metadata":{"id":"LH3NcDI-2qhn","outputId":"86c15334-cb2c-4af3-d17e-a346dadd87f9","execution":{"iopub.status.busy":"2022-07-31T11:07:12.871357Z","iopub.execute_input":"2022-07-31T11:07:12.872008Z","iopub.status.idle":"2022-07-31T11:07:13.160131Z","shell.execute_reply.started":"2022-07-31T11:07:12.871969Z","shell.execute_reply":"2022-07-31T11:07:13.159091Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(y[0].shape)\nprint(np.unique(y[0], return_counts= True))","metadata":{"id":"IuYej9OjVSKR","outputId":"29bf1556-fc00-41fb-efb6-545e0304b3f3","execution":{"iopub.status.busy":"2022-07-31T11:07:13.163220Z","iopub.execute_input":"2022-07-31T11:07:13.163776Z","iopub.status.idle":"2022-07-31T11:07:13.170353Z","shell.execute_reply.started":"2022-07-31T11:07:13.163745Z","shell.execute_reply":"2022-07-31T11:07:13.169448Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели","metadata":{"id":"1YAU_j9TOJJz"}},{"cell_type":"code","source":"def downblock(filters, filter_size, previous_layer):\n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(previous_layer)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n \n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n  \n    residual = layers.Conv2D(filters, 1, padding=\"same\")(previous_layer)      #separate layer for addintion\n    x = layers.add([x, residual])  # Add back residual\n \n    x = layers.Activation(\"relu\")(x)\n    p = layers.MaxPooling2D(2)(x)\n \n    return x,p\n \ndef bottleneck(filters, filter_size, previous_layer):\n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(previous_layer)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.Dropout(.5)(x)\n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n \n    residual = layers.Conv2D(filters, 1, padding=\"same\")(previous_layer)      #separate layer for addintion\n    x = layers.add([x, residual])  # Add back residual\n  \n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n \n    return x\n \ndef upblock(filters, filter_size, previous_layer, layer_to_concat):\n    x = layers.Conv2DTranspose(filters, filter_size, strides=2, padding=\"same\")(previous_layer)       #upconvolution\n    concat = layers.concatenate([x, layer_to_concat])                                                      #concatenation\n \n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(concat)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    x = layers.Conv2D(filters, filter_size, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n \n    residual = layers.Conv2D(filters, 1, padding=\"same\")(concat)      #separate layer for addintion\n    x = layers.add([x, residual])  # Add back residual\n  \n    x = layers.Activation(\"relu\")(x)\n \n    return x","metadata":{"id":"mZIb-A942qmN","execution":{"iopub.status.busy":"2022-07-31T11:07:13.171622Z","iopub.execute_input":"2022-07-31T11:07:13.172629Z","iopub.status.idle":"2022-07-31T11:07:13.187302Z","shell.execute_reply.started":"2022-07-31T11:07:13.172577Z","shell.execute_reply":"2022-07-31T11:07:13.186419Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"input_layer = layers.Input(shape = img_size + (3,))\n \nconv1, pool1 = downblock(32, 3, input_layer)\nconv2, pool2 = downblock(64, 3, pool1)\nconv3, pool3 = downblock(128, 3, pool2)\nconv4, pool4 = downblock(256, 3, pool3)\n \nconv5 = bottleneck(512,3,pool4)\n\nupconv1 = upblock(256, 3, conv5, conv4) \nupconv2 = upblock(128, 3, upconv1, conv3)\nupconv3 = upblock(64, 3, upconv2, conv2)\nupconv4 = upblock(32, 3, upconv3, conv1)\n \noutput_layer = layers.Conv2D(1, 1, padding=\"same\", activation='sigmoid')(upconv4)\nmodel = keras.Model(input_layer, output_layer)\nmodel.summary()","metadata":{"id":"HoPTrlJN5jHU","outputId":"c3413523-85f2-4f3e-8641-9cc8be96874d","execution":{"iopub.status.busy":"2022-07-31T11:07:13.193641Z","iopub.execute_input":"2022-07-31T11:07:13.193920Z","iopub.status.idle":"2022-07-31T11:07:16.620108Z","shell.execute_reply.started":"2022-07-31T11:07:13.193888Z","shell.execute_reply":"2022-07-31T11:07:16.619060Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"img_file = \"./combined.png\"\ntf.keras.utils.plot_model(model, to_file= img_file, show_shapes=True, show_layer_names=True)","metadata":{"id":"VQimD4fJIFgX","outputId":"4ea38ce8-c9d8-4ea6-ef7a-b54ea7b4e540","execution":{"iopub.status.busy":"2022-07-31T11:07:16.624374Z","iopub.execute_input":"2022-07-31T11:07:16.626657Z","iopub.status.idle":"2022-07-31T11:07:19.195317Z","shell.execute_reply.started":"2022-07-31T11:07:16.626619Z","shell.execute_reply":"2022-07-31T11:07:19.194307Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nopt = Adam(learning_rate=0.001)\n \nmodel.compile(optimizer=opt, loss=\"binary_crossentropy\", \n              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)]) # metrics=[tf.keras.metrics.MeanIoU(num_classes=2)]\n \nfilepath = \"./model_epoch_{epoch:00d}_val_loss_{val_loss:03f}.h5\"\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, save_best_only= False)\n \ncallbacks = [checkpoint]","metadata":{"id":"mOoEa6M72qeK","execution":{"iopub.status.busy":"2022-07-31T11:07:19.197111Z","iopub.execute_input":"2022-07-31T11:07:19.197690Z","iopub.status.idle":"2022-07-31T11:07:19.471386Z","shell.execute_reply.started":"2022-07-31T11:07:19.197653Z","shell.execute_reply":"2022-07-31T11:07:19.470461Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"start = datetime.now()\n \n# Train the model, doing validation at the end of each epoch.\nepochs = 5\nmodel_history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)\n \nend = datetime.now()\nprint(f'Time take to train {epochs} epochs is:', end - start)","metadata":{"id":"FlffcLVjcEji","outputId":"8518515a-c5a3-47c4-9706-429c9d971e10","execution":{"iopub.status.busy":"2022-07-31T11:07:19.472773Z","iopub.execute_input":"2022-07-31T11:07:19.473128Z","iopub.status.idle":"2022-07-31T14:55:56.643952Z","shell.execute_reply.started":"2022-07-31T11:07:19.473094Z","shell.execute_reply":"2022-07-31T14:55:56.641719Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"    Epoch 1/5\n    9621/9621 [==============================] - 2631s 272ms/step - loss: 0.1776 - accuracy: 0.9269 - mean_io_u: 0.4290 - val_loss: 0.2519 - val_accuracy: 0.9087 - val_mean_io_u: 0.4162\n    Epoch 2/5\n    9621/9621 [==============================] - 2753s 286ms/step - loss: 0.1169 - accuracy: 0.9528 - mean_io_u: 0.4290 - val_loss: 0.2212 - val_accuracy: 0.9145 - val_mean_io_u: 0.4162\n    Epoch 3/5\n    9621/9621 [==============================] - 2748s 286ms/step - loss: 0.1022 - accuracy: 0.9591 - mean_io_u: 0.4290 - val_loss: 0.2340 - val_accuracy: 0.9169 - val_mean_io_u: 0.4162\n    Epoch 4/5\n    9621/9621 [==============================] - 2737s 284ms/step - loss: 0.0929 - accuracy: 0.9630 - mean_io_u: 0.4290 - val_loss: 0.2172 - val_accuracy: 0.9222 - val_mean_io_u: 0.4162\n    Epoch 5/5\n    9621/9621 [==============================] - 2847s 296ms/step - loss: 0.0860 - accuracy: 0.9659 - mean_io_u: 0.4290 - val_loss: 0.2364 - val_accuracy: 0.9228 - val_mean_io_u: 0.4162\n    \n**Time take to train 5 epochs is: 3:48:37.163636**","metadata":{}},{"cell_type":"code","source":"model_history.history ","metadata":{"id":"rOuEHk4CRSX1","outputId":"2d9bfd80-c1ad-4c45-a807-0e68e1440ca6","execution":{"iopub.status.busy":"2022-07-31T14:55:56.649153Z","iopub.execute_input":"2022-07-31T14:55:56.649446Z","iopub.status.idle":"2022-07-31T14:55:56.657195Z","shell.execute_reply.started":"2022-07-31T14:55:56.649419Z","shell.execute_reply":"2022-07-31T14:55:56.656231Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"history = model_history.history ","metadata":{"id":"xnDsgL2OiJhi","execution":{"iopub.status.busy":"2022-07-31T14:55:56.674957Z","iopub.execute_input":"2022-07-31T14:55:56.675352Z","iopub.status.idle":"2022-07-31T14:55:56.680557Z","shell.execute_reply.started":"2022-07-31T14:55:56.675317Z","shell.execute_reply":"2022-07-31T14:55:56.679497Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_loss = history['loss']\nval_loss = history['val_loss']\ntrain_acc = history['accuracy']\nval_acc = history['val_accuracy']\ntrain_iou = history['mean_io_u']\nval_iou = history['val_mean_io_u']\n\nplt.figure(figsize=(14,6))\n\nplt.subplot(1,3,1)\nplt.plot(train_loss, 'r', label='Training loss')\nplt.plot(val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss Value')\nplt.yticks(np.arange(0, .5,.05))\nplt.legend()\n\nplt.subplot(1,3,2)\nplt.plot(train_acc, 'r', label='Training acc')\nplt.plot(val_acc, 'b', label='Validation acc')\nplt.title('Training and Validation acc')\nplt.xlabel('Epoch')\nplt.ylabel('acc')\nplt.yticks(np.arange(0,1.1,.1))\nplt.legend()\n\nplt.subplot(1,3,3)\nplt.plot(train_iou, 'r', label='Training mean_io_u')\nplt.plot(val_iou, 'b', label='Validation mean_io_u')\nplt.title('Training and Validation mean_io_u')\nplt.xlabel('Epoch')\nplt.ylabel('mean_io_u')\nplt.yticks(np.arange(0,1,.05))\nplt.legend()\nplt.show()","metadata":{"id":"Y2nkI8p6QpLk","outputId":"4a539885-405c-4069-fa35-512571bf6549","execution":{"iopub.status.busy":"2022-07-31T14:55:56.682287Z","iopub.execute_input":"2022-07-31T14:55:56.683180Z","iopub.status.idle":"2022-07-31T14:55:57.169428Z","shell.execute_reply.started":"2022-07-31T14:55:56.683143Z","shell.execute_reply":"2022-07-31T14:55:57.168536Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Тестирование","metadata":{"id":"Hy8bTrhrwS1C"}},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-07-31T14:55:57.170808Z","iopub.execute_input":"2022-07-31T14:55:57.171265Z","iopub.status.idle":"2022-07-31T14:55:57.176920Z","shell.execute_reply.started":"2022-07-31T14:55:57.171221Z","shell.execute_reply":"2022-07-31T14:55:57.175753Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(f\"./model_epoch_{epochs}_val_loss_{str(history['val_loss'][-1])[:8]}.h5\")","metadata":{"id":"yrCIWWAPplTU","execution":{"iopub.status.busy":"2022-07-31T14:55:57.178950Z","iopub.execute_input":"2022-07-31T14:55:57.179914Z","iopub.status.idle":"2022-07-31T14:55:58.109151Z","shell.execute_reply.started":"2022-07-31T14:55:57.179847Z","shell.execute_reply":"2022-07-31T14:55:58.108162Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def ploting(imgpath, maskpath):\n    plt.figure(figsize=(18,6))\n\n    im = io.imread(imgpath)\n    im = cv2.resize(im,img_size)\n    im = np.array(im)/255\n\n    plt.subplot(1,3,1)\n    plt.title('Original')\n    plt.imshow(im)\n\n    im = im.reshape((1,)+im.shape)\n    im.shape\n\n    pred = model.predict(im)\n\n    p = pred.copy()\n    p = p.reshape(p.shape[1:-1])\n\n    p[np.where(p>.2)] = 1\n    p[np.where(p<.2)] = 0\n\n    im = io.imread(imgpath)\n    im = cv2.resize(im,img_size)\n    im = np.array(im)\n\n    im[:,:,0] = im[:,:,0]*p \n    im[:,:,0][np.where(p!=1)] = 247\n    im[:,:,1] = im[:,:,1]*p \n    im[:,:,1][np.where(p!=1)] = 231\n    im[:,:,2] = im[:,:,2]*p\n    im[:,:,2][np.where(p!=1)] = 230\n\n    plt.subplot(1,3,2)\n    plt.imshow(im)\n\n    if maskpath:\n        plt.subplot(1,3,3)\n        mask = io.imread(maskpath)\n        plt.imshow(mask)\n\n        plt.show()","metadata":{"id":"odVqKYpXRfAb","execution":{"iopub.status.busy":"2022-07-31T14:55:58.110845Z","iopub.execute_input":"2022-07-31T14:55:58.111188Z","iopub.status.idle":"2022-07-31T14:55:58.125949Z","shell.execute_reply.started":"2022-07-31T14:55:58.111152Z","shell.execute_reply":"2022-07-31T14:55:58.124968Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Результаты на валидационной выборке","metadata":{}},{"cell_type":"code","source":"n_images = 5\nfor i in np.random.randint(0,len(val_input_img_paths),n_images):\n    ploting(val_input_img_paths[i], val_target_img_paths[i])","metadata":{"id":"eQOoM2tR64pK","outputId":"2c4e1184-5302-4396-b77f-7f8ce60c1352","execution":{"iopub.status.busy":"2022-07-31T14:55:58.127654Z","iopub.execute_input":"2022-07-31T14:55:58.128011Z","iopub.status.idle":"2022-07-31T14:56:01.825894Z","shell.execute_reply.started":"2022-07-31T14:55:58.127974Z","shell.execute_reply":"2022-07-31T14:56:01.825002Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Красивый вывод результатов тестирования","metadata":{"id":"A8VpsDLIQ6GK"}},{"cell_type":"code","source":"def plot_and_save(imgpath):\n    plt.figure(figsize=(18,6))\n\n    im = io.imread(imgpath)\n    im_orig_size = im.shape[:-1]\n    im = cv2.resize(im,img_size)\n    im = np.array(im)/255\n\n    plt.subplot(1,3,1)\n    plt.title('Original')\n    plt.imshow(im)\n\n    im = im.reshape((1,)+im.shape)\n    im.shape\n\n    pred = model.predict(im)\n\n    p = pred.copy()\n    p = p.reshape(p.shape[1:-1])\n\n    p[np.where(p>.2)] = 1\n    p[np.where(p<.2)] = 0\n\n    im = io.imread(imgpath)\n    im = cv2.resize(im,img_size)\n    im = np.array(im)\n\n    im[:,:,0] = im[:,:,0]*p \n    im[:,:,0][np.where(p!=1)] = 247\n    im[:,:,1] = im[:,:,1]*p \n    im[:,:,1][np.where(p!=1)] = 231\n    im[:,:,2] = im[:,:,2]*p\n    im[:,:,2][np.where(p!=1)] = 230\n\n    plt.subplot(1,3,2)\n    # im = cv2.resize(im,im_orig_size[::-1])\n    plt.imshow(im)\n\n    im = cv2.resize(im,im_orig_size[::-1])\n    im = Image.fromarray(im)\n    im.save(f\"without_bg_{imgpath[2:]}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-31T14:56:01.827403Z","iopub.execute_input":"2022-07-31T14:56:01.827953Z","iopub.status.idle":"2022-07-31T14:56:01.842331Z","shell.execute_reply.started":"2022-07-31T14:56:01.827917Z","shell.execute_reply":"2022-07-31T14:56:01.841356Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"!wget https://m.media-amazon.com/images/M/MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg","metadata":{"execution":{"iopub.status.busy":"2022-07-31T14:56:01.844822Z","iopub.execute_input":"2022-07-31T14:56:01.845542Z","iopub.status.idle":"2022-07-31T14:56:03.746129Z","shell.execute_reply.started":"2022-07-31T14:56:01.845501Z","shell.execute_reply":"2022-07-31T14:56:03.744991Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"![](./MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg)","metadata":{}},{"cell_type":"code","source":"plot_and_save(\"./MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg\")","metadata":{"id":"2nMGmCWvrAtF","outputId":"747128d1-e428-47d3-8abc-13675ff8326f","execution":{"iopub.status.busy":"2022-07-31T14:56:03.749945Z","iopub.execute_input":"2022-07-31T14:56:03.750260Z","iopub.status.idle":"2022-07-31T14:56:04.288418Z","shell.execute_reply.started":"2022-07-31T14:56:03.750232Z","shell.execute_reply":"2022-07-31T14:56:04.287525Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"![](./without_bg_MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg)","metadata":{}},{"cell_type":"code","source":"!rm -r pic.png\n!rm -r ./w_bg.png\n\nim = Image.open('./without_bg_MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg')\nim.save('pic.png')\n\ndef magic(img_path, orig_path):\n    img = Image.open(img_path)\n    orig = Image.open(orig_path)\n    \n    img = img.convert(\"RGBA\")\n    orig = orig.convert(\"RGBA\")\n    datas = img.getdata()\n    orig_data = orig.getdata()\n\n    newData = []\n    colors = [247, 231, 230]\n    for item, item_orig in zip(datas, orig_data):\n        if item[0] in colors or item[1] in colors or item[2] in colors:\n            newData.append((255, 255, 255, 0))\n        else:\n            newData.append(item_orig)\n\n    img.putdata(newData)\n    img.save(f\"w_bg.png\", \"PNG\")\n    \nmagic('pic.png', \"./MV5BNDMzNWE3N2QtY2Q5MS00N2M2LTk0YjctMWEzNWYyYWI0YTgxXkEyXkFqcGdeQXVyMjMzMDI4MjQ@._V1_.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-07-31T14:56:04.289829Z","iopub.execute_input":"2022-07-31T14:56:04.290474Z","iopub.status.idle":"2022-07-31T14:56:07.389131Z","shell.execute_reply.started":"2022-07-31T14:56:04.290438Z","shell.execute_reply":"2022-07-31T14:56:07.387985Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"![](./w_bg.png)","metadata":{}},{"cell_type":"markdown","source":"# Источники:\n\n* [COCO-Person-Segmentation](https://www.kaggle.com/datasets/oishee30/cocopersonsegmentation)\n* [Person segmentation dataset](https://www.kaggle.com/datasets/furkankati/person-segmentation-dataset)\n* [Automatic_Background_Removal](https://github.com/G0rav/Automatic_Background_Removal)\n* [COCO датасет](https://cocodataset.org/#home)\n* [Background removal with deep learning](https://towardsdatascience.com/background-removal-with-deep-learning-c4f2104b3157)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"_K1qEU9RtDFI"},"execution_count":null,"outputs":[]}]}